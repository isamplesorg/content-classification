{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745e28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer,BertForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn import preprocessing\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ddb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_MODE\"]=\"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3403471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create custom dataset \n",
    "class MulticlassDataset(Dataset):\n",
    "\n",
    "    def __init__(self, encodings, labels):\n",
    "      self.encodings = encodings\n",
    "      self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f475905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataframe, selected_material_type=None):\n",
    "  #convert the dataframe labels accordingly by the material type\n",
    "  if selected_material_type!=\"None\":\n",
    "    new_df = dataframe.copy()\n",
    "    for _, row in new_df.iterrows():\n",
    "      if row['description_material'].split(\"_\")[0] == selected_material_type:\n",
    "        continue #leave the label\n",
    "      else:\n",
    "        row['description_material']=\"None\" #set none as label\n",
    "  else:\n",
    "    new_df = dataframe.copy()   #flattened label version \n",
    "  new_df\n",
    "  #convert labels into integers\n",
    "  le.fit(new_df.description_material)\n",
    "\n",
    "  new_df['description_material'] = le.transform(new_df.description_material)\n",
    "  print(selected_material_type, \" number of labels: \", len(le.classes_))\n",
    "  #split data to training df, val df, test df\n",
    "  train_df, dev_df, test_df =  np.split(new_df.sample(frac=1, random_state=42),[int(.6*len(new_df)), int(.8*len(new_df))])\n",
    " \n",
    "  return train_df, dev_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573127d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, tokenizer):\n",
    "  max_length = 64\n",
    "  inputs = {\n",
    "          \"input_ids\":[],\n",
    "          \"attention_mask\":[]\n",
    "        }\n",
    "  features_columns =[x for x in dataframe.columns.values if x != 'description_material' and x.startswith(\"description\")]\n",
    "  def create_concatenated_text(dataframe):\n",
    "    \"\"\"combine the columns text to create a single sentence\"\"\"\n",
    "    sents= [] #text that is a concatenation of all columns\n",
    "    for _, row in dataframe.iterrows():\n",
    "      combined = \"\"\n",
    "      for col in features_columns:\n",
    "        row_value = row[col]\n",
    "        if row_value!=\"\" and type(row_value)==str:\n",
    "          combined+= row_value +\" , \"\n",
    "      sents.append(combined)\n",
    "    return sents\n",
    "  sents = create_concatenated_text(dataframe)\n",
    "  for sent in sents:\n",
    "    tokenized_input = tokenizer(sent,max_length=MAX_LENGTH, padding='max_length', truncation=True)\n",
    "    inputs[\"input_ids\"].append(torch.tensor(tokenized_input[\"input_ids\"]))\n",
    "    inputs[\"attention_mask\"].append(torch.tensor(tokenized_input[\"attention_mask\"]))\n",
    "\n",
    "  labels = torch.tensor(dataframe['description_material'].values.tolist())\n",
    "\n",
    "  return MulticlassDataset(inputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4763b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_class_weights(dataframe):\n",
    "  \"\"\"computes the class weight and returns a list to account for class imbalance \"\"\"\n",
    "  labels = torch.tensor(dataframe['description_material'].values.tolist())\n",
    "  class_weights=compute_class_weight( class_weight ='balanced',classes = np.unique(labels),y = labels.numpy())\n",
    "\n",
    "  total_class_weights =torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    "  return total_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3bc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_trainer(class_weights):\n",
    "  \"\"\"creates custom trainer that accounts for class imbalance\"\"\"\n",
    "  class CustomTrainer(Trainer):\n",
    "      def compute_loss(self, model, inputs, return_outputs=False):\n",
    "          labels = inputs.get(\"labels\")\n",
    "          # forward pass\n",
    "          outputs = model(**inputs)\n",
    "          logits = outputs.get(\"logits\")\n",
    "          # compute custom loss \n",
    "          loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "          loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "          return (loss, outputs) if return_outputs else loss\n",
    "  return CustomTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(selected_type, dataframe, tokenizer, batch_size, train_mode, MODEL_DIR, OUTPUT_DIR):\n",
    "\n",
    "  train_df, dev_df, test_df = preprocess(dataframe,selected_type)\n",
    "  test_dataset = create_dataset(test_df,tokenizer)\n",
    "\n",
    "  #load model\n",
    "  model = BertForSequenceClassification.from_pretrained(MODEL_DIR, num_labels = len(le.classes_), )\n",
    "\n",
    "  # Tell pytorch to run this model on the GPU.\n",
    "  desc = model.cuda()\n",
    "\n",
    "  test_args = TrainingArguments(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = batch_size,   \n",
    "  )\n",
    "  #get class weight\n",
    "  class_weights = get_class_weights(train_df)\n",
    "  CustomTrainer = create_custom_trainer(class_weights)\n",
    "\n",
    "  if train_mode == \"custom\":\n",
    "    trainer = CustomTrainer(model = model, args =test_args)\n",
    "  else:\n",
    "    trainer = Trainer(model = model, args =test_args)\n",
    "\n",
    "  #conduct evaluation \n",
    "  keys = []\n",
    "  precision = []\n",
    "  recall = []\n",
    "  f1 = []\n",
    "  \n",
    "  logits = trainer.predict(test_dataset)[0] #get the logits \n",
    "  test_pred = np.argmax(logits,axis=-1)\n",
    "  y_test= torch.tensor(test_df['description_material'].values.tolist())\n",
    "  res = classification_report(y_test,test_pred,output_dict=True)\n",
    "  for key, score in res.items():\n",
    "    if key.isdigit():\n",
    "      keys.append((le.inverse_transform([int(key)])[0]))\n",
    "      precision.append(round(score['precision'],2))\n",
    "      recall.append(round(score['recall'],2))\n",
    "      f1.append(round(score['f1-score'],2))\n",
    "      print(\"%s \\t\\t\\t %0.2f \\t %0.2f \\t %0.2f\"% (le.inverse_transform([int(key)])[0],score['precision'], score['recall'], score['f1-score']))\n",
    "  #write the results to excel and save\n",
    "  result_df = pd.DataFrame(data=zip(keys,precision,recall,f1), columns=['label','precision','recall','f1'])\n",
    "  result_output_dir =OUTPUT_DIR+\"/sesar_result.xlsx\"\n",
    "  result_df.to_excel(result_output_dir)\n",
    "  print(\"Macro average: \",f1_score(y_test,test_pred,average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4552f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7995a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "   ## Required parameters\n",
    "\n",
    "batch_size=int(10)\n",
    "\n",
    "train_mode=str('FALSE')\n",
    "          #\"Whether we account for class imbalance during training by using a custom trainer (custom) or not (none)\",\n",
    "\n",
    "model_dir=str('output\\checkpoint-14')\n",
    "   #Directory where the finetuned model is saved\",\n",
    "                   \n",
    "output_dir =str('evaloutput')\n",
    "   #Output directory where the model checkpoint will be saved\",\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e985939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iSamplesMaterialTrainingSmall.csv\")\n",
    "df = df.fillna(\"\")\n",
    "    #remove rows that do not have a material type\n",
    "df = df[df[\"description_material\"]!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cdc2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #load tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', do_lower_case=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de48854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None  number of labels:  3\n"
     ]
    }
   ],
   "source": [
    "# train    (args.material_type, df,        tokenizer, args.batch_size,args.lr_rate, args.nb_epochs, args.train_mode, args.model_dir, args.output_dir)\n",
    "# def train(selected_type,      dataframe, tokenizer, batch_size,                                   train_mode,   MODEL_DIR, OUTPUT_DIR):\n",
    "# put function in line for testing...\n",
    "\n",
    "train_df, dev_df, test_df = preprocess(df)\n",
    "test_dataset = create_dataset(test_df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb32fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #load model\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir, num_labels = len(le.classes_), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e26976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "  # Tell pytorch to run this model on the selected device\n",
    "    # If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "# desc = model.cuda()\n",
    "desc = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b05052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = batch_size,   \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45e29f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #get class weight\n",
    "class_weights = get_class_weights(train_df)\n",
    "CustomTrainer = create_custom_trainer(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd76f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode == \"custom\":\n",
    "    trainer = CustomTrainer(model = model, args =test_args)\n",
    "else:\n",
    "    trainer = Trainer(model = model, args =test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3339f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  #conduct evaluation \n",
    "keys = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "  \n",
    "logits = trainer.predict(test_dataset)[0] #get the logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad7b793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.argmax(logits,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c97ddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\sampleclass\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\envs\\sampleclass\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\envs\\sampleclass\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_test= torch.tensor(test_df['description_material'].values.tolist())\n",
    "res = classification_report(y_test,test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cebfa922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat:rock \t\t\t 0.95 \t 1.00 \t 0.98\n",
      "mat:soil \t\t\t 0.00 \t 0.00 \t 0.00\n",
      "Macro average:  0.48837209302325585\n"
     ]
    }
   ],
   "source": [
    "for key, score in res.items():\n",
    "    if key.isdigit():\n",
    "      keys.append((le.inverse_transform([int(key)])[0]))\n",
    "      precision.append(round(score['precision'],2))\n",
    "      recall.append(round(score['recall'],2))\n",
    "      f1.append(round(score['f1-score'],2))\n",
    "      print(\"%s \\t\\t\\t %0.2f \\t %0.2f \\t %0.2f\"% (le.inverse_transform([int(key)])[0],score['precision'], score['recall'], score['f1-score']))\n",
    "#write the results to excel and save\n",
    "result_df = pd.DataFrame(data=zip(keys,precision,recall,f1), columns=['label','precision','recall','f1'])\n",
    "result_output_dir =output_dir+\"/sesar_result.xlsx\"\n",
    "result_df.to_excel(result_output_dir)\n",
    "print(\"Macro average: \",f1_score(y_test,test_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b2c3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]),\n",
       "  tensor([102, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0])],\n",
       " 'attention_mask': [tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9899ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
