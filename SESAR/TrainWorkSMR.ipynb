{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed4a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_MODE\"]=\"disabled\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "#!export CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63c2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer,BertForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn import preprocessing\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10698e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# use this to map categories to integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925724d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfaff96",
   "metadata": {},
   "source": [
    "functions and class definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba50c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassDataset(Dataset):\n",
    "\n",
    "    def __init__(self, encodings, labels):\n",
    "      self.encodings = encodings\n",
    "      self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c732a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataframe, selected_material_type=None):\n",
    "  #convert the dataframe labels accordingly by the material type\n",
    "  if selected_material_type!=\"None\":\n",
    "    new_df = dataframe.copy()\n",
    "    for _, row in new_df.iterrows():\n",
    "      if row['iSampleMaterial'].split(\"_\")[0] == selected_material_type:\n",
    "        continue #leave the label\n",
    "      else:\n",
    "        row['iSampleMaterial']=\"None\" #set none as label\n",
    "  else:\n",
    "    new_df = dataframe.copy()   #flattened label version \n",
    "  new_df\n",
    "  #convert labels into integers\n",
    "  le.fit(new_df.iSampleMaterial)\n",
    "\n",
    "  new_df['iSampleMaterial'] = le.transform(new_df.iSampleMaterial)\n",
    "  print(\" number of labels: \", len(le.classes_))\n",
    "  #split data to training df, val df, test df\n",
    "  sample_size = 10000\n",
    "  fraction=sample_size/len(new_df)  # get about 500 samples\n",
    "  sel_len = sample_size\n",
    "  train_df, dev_df, test_df =  np.split(new_df.sample(frac=fraction, random_state=42),[int(.6*sel_len), int(.8*sel_len)])\n",
    "\n",
    "  train_df.to_csv('output/train_df.csv')\n",
    "  dev_df.to_csv('output/dev_df.csv')\n",
    "  test_df.to_csv('output/test_df.csv')\n",
    " \n",
    "  return train_df, dev_df, test_df\n",
    "\n",
    "\n",
    "def create_dataset(dataframe, tokenizer):\n",
    "  MAX_LENGTH = 80\n",
    "  inputs = {\n",
    "          \"input_ids\":[],\n",
    "          \"attention_mask\":[]\n",
    "        }\n",
    "    \n",
    "  features_columns =[x for x in dataframe.columns.values if x != 'iSampleMaterial']\n",
    "  def create_concatenated_text(dataframe):\n",
    "    \"\"\"combine the columns text to create a single sentence\"\"\"\n",
    "    sents= [] #text that is a concatenation of all columns\n",
    "    for _, row in dataframe.iterrows():\n",
    "      combined = \"\"\n",
    "#      for col in features_columns:\n",
    "      row_value = row[\"text\"]\n",
    "      if row_value!=\"\" and type(row_value)==str:\n",
    "          combined += row_value   # +\" , \"\n",
    "      sents.append(combined)\n",
    "    return sents\n",
    "\n",
    "  sents = create_concatenated_text(dataframe)\n",
    "  for sent in sents:\n",
    "    tokenized_input = tokenizer(sent,max_length=MAX_LENGTH, padding='max_length', truncation=True)\n",
    "    inputs[\"input_ids\"].append(torch.tensor(tokenized_input[\"input_ids\"]))\n",
    "    inputs[\"attention_mask\"].append(torch.tensor(tokenized_input[\"attention_mask\"]))\n",
    " \n",
    "  print(\"torch tensor dataframe columns:\", dataframe.columns.values)\n",
    "  #print(\"dataframe['iSampleMaterial']: \",dataframe['iSampleMaterial'].values )\n",
    "  labels = torch.tensor(dataframe['iSampleMaterial'].values.tolist())\n",
    "    \n",
    "  return MulticlassDataset(inputs,labels)\n",
    "\n",
    "def get_class_weights(dataframe):\n",
    "  \"\"\"computes the class weight and returns a list to account for class imbalance \"\"\"\n",
    "  labels = torch.tensor(dataframe['iSampleMaterial'].values.tolist())\n",
    "  class_weights=compute_class_weight( class_weight ='balanced',classes = np.unique(labels),y = labels.numpy())\n",
    "\n",
    "  total_class_weights =torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    "  return total_class_weights\n",
    "\n",
    "def create_custom_trainer(class_weights):\n",
    "  \"\"\"creates custom trainer that accounts for class imbalance\"\"\"\n",
    "  class CustomTrainer(Trainer):\n",
    "      def compute_loss(self, model, inputs, return_outputs=False):\n",
    "          labels = inputs.get(\"labels\")\n",
    "          # forward pass\n",
    "          outputs = model(**inputs)\n",
    "          logits = outputs.get(\"logits\")\n",
    "          # compute custom loss \n",
    "          loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "          loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "          return (loss, outputs) if return_outputs else loss\n",
    "  return CustomTrainer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550b8a4",
   "metadata": {},
   "source": [
    "def train(selected_type, dataframe, tokenizer, batch_size, learning_rate, epochs,train_mode, output_dir):\n",
    "\n",
    "  train_df, dev_df, test_df = preprocess(dataframe,selected_type)\n",
    "  train_dataset = create_dataset(train_df, tokenizer)\n",
    "  dev_dataset = create_dataset(dev_df,tokenizer)\n",
    "  test_dataset = create_dataset(test_df,tokenizer)\n",
    "\n",
    "  #load model\n",
    "  model = BertForSequenceClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\", num_labels = len(le.classes_), )\n",
    "\n",
    "  # Tell pytorch to run this model on the GPU.\n",
    "  #desc = model.cuda()\n",
    "  desc = model.to(device)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir= output_dir,     # output directory\n",
    "          num_train_epochs=epochs,              # total number of training epochs\n",
    "          per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "          per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "          learning_rate = learning_rate,\n",
    "          warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "          weight_decay=0.01, \n",
    "          load_best_model_at_end=True,            \n",
    "          logging_dir=output_dir,            # directory for storing logs\n",
    "          logging_steps=10,\n",
    "          evaluation_strategy = \"epoch\", #To calculate metrics per epoch\n",
    "          save_strategy = \"epoch\"\n",
    "  )\n",
    "  #get class weight\n",
    "  class_weights = get_class_weights(train_df)\n",
    "  CustomTrainer = create_custom_trainer(class_weights)\n",
    "\n",
    "  if train_mode == \"custom\":\n",
    "    trainer = CustomTrainer(model = model, args =training_args, train_dataset=train_dataset, eval_dataset=dev_dataset)\n",
    "  else:\n",
    "    trainer = Trainer(model = model, args =training_args, train_dataset=train_dataset, eval_dataset=dev_dataset)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427fa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(dataframe):\n",
    "    \n",
    "  le.fit(dataframe.iSampleMaterial)\n",
    "  print(\" number of labels: \", len(le.classes_))\n",
    "  print(\"label encoder classes:\",le.classes_)\n",
    "  rockint = le.transform([\"mat:rock\"])[0]\n",
    "  #convert the dataframe labels accordingly by the material type\n",
    "  # want to sample the different material types according to their frequency\n",
    "  # generate separate dataframes for mineral, rock, sediment, rockorsediment, and soil\n",
    "\n",
    "  # fraction of total for each class\n",
    "  #min_n = .255\n",
    "  #rock_n = .435\n",
    "  #sed_n = .125\n",
    "  #rocksed_n = .065\n",
    "  #soil_n = .12\n",
    "\n",
    "#try different distribution\n",
    "  min_n = .205\n",
    "  rock_n = .235\n",
    "  sed_n = .225\n",
    "  rocksed_n = .215\n",
    "  soil_n = .12\n",
    "  # total sample \n",
    "  sample_size = 1000\n",
    "  #rand_state = int(42)\n",
    "  rand_state = int(19)\n",
    "  \n",
    "  \n",
    "  #split data to training df, val df, test df\n",
    "  min_df = dataframe[dataframe[\"iSampleMaterial\"]==\"mat:mineral\"].copy()   #flattened label version \n",
    "    # build the data frames\n",
    "  print(\"min_df rowcount: \", len(min_df.index))\n",
    "  this_n = int(round(min_n * sample_size, 0))  # weights='weight', axis=0,\n",
    "  train_df_min, dev_df_min, test_df_min =  np.split(min_df.sample(n=this_n,   random_state=rand_state),[int(.6*this_n), int(.8*this_n)])\n",
    "  print(\"finished min dataframe. this_n:\", this_n, \" split at:\",int(.6*this_n), int(.8*this_n))\n",
    "\n",
    "  rock_df = dataframe[dataframe[\"iSampleMaterial\"]==\"mat:rock\"].copy()   #flattened label version \n",
    "    # build the data frames\n",
    "  this_n = int(round(rock_n * sample_size, 0))  # weights='weight', axis=0,\n",
    "  train_df_rock, dev_df_rock, test_df_rock =  np.split(rock_df.sample(n=this_n,   random_state=rand_state),[int(.6*this_n), int(.8*this_n)])\n",
    "  print(\"finished rock dataframe. this_n:\", this_n, \" split at:\",int(.6*this_n), int(.8*this_n))\n",
    "\n",
    "    \n",
    "  sed_df = dataframe[dataframe[\"iSampleMaterial\"]==\"mat:sediment\"].copy()   #flattened label version \n",
    "    # build the data frames\n",
    "  this_n = int(round(sed_n * sample_size, 0))  # weights='weight', axis=0,\n",
    "  train_df_sed, dev_df_sed, test_df_sed =  np.split(sed_df.sample(n=this_n,   random_state=rand_state),[int(.6*this_n), int(.8*this_n)])\n",
    "  print(\"finished sed dataframe. this_n:\", this_n, \" split at:\",int(.6*this_n), int(.8*this_n))\n",
    "\n",
    "\n",
    "  rocksed_df = dataframe[dataframe[\"iSampleMaterial\"]==\"mat:rockorsediment\"].copy()   #flattened label version \n",
    "    # build the data frames\n",
    "  this_n = int(round(rocksed_n * sample_size, 0)) # weights='weight', axis=0,\n",
    "  train_df_rocksed, dev_df_rocksed, test_df_rocksed =  np.split(rocksed_df.sample(n=this_n,   random_state=rand_state),[int(.6*this_n), int(.8*this_n)])\n",
    "  print(\"finished rocksed dataframe. this_n:\", this_n, \" split at:\",int(.6*this_n), int(.8*this_n))\n",
    "\n",
    "\n",
    "  soil_df = dataframe[dataframe[\"iSampleMaterial\"]==\"mat:soil\"].copy()   #flattened label version \n",
    "    # build the data frames\n",
    "  this_n = int(round(soil_n * sample_size, 0)) # weights='weight', axis=0,\n",
    "  train_df_soil, dev_df_soil, test_df_soil =  np.split(soil_df.sample(n=this_n,   random_state=rand_state),[int(.6*this_n), int(.8*this_n)])\n",
    "  print(\"finished soil dataframe. this_n:\", this_n, \" split at:\",int(.6*this_n), int(.8*this_n))\n",
    "\n",
    "    \n",
    "  #train_df_soil.to_csv('output/train_df_soil.csv')\n",
    "  #dev_df_soil.to_csv('output/dev_df_soil.csv')\n",
    "  #test_df_soil.to_csv('output/test_df_soil.csv')\n",
    "    \n",
    "    \n",
    "#intention is for final dataset for training to have sample_size records, distributed over the 5 classes based on the abundance of the class\n",
    "#  and weighted according to the frequency distribution for the 154 IGSN registrants. Based on \n",
    "#  assumption that a given registrant will be documenting similar samples with similar conventions\n",
    "    \n",
    "# merge the training dataframes\n",
    "  theframes = [train_df_min, train_df_rock, train_df_sed,train_df_rocksed,train_df_soil]\n",
    "  train_df = pd.concat(theframes)\n",
    "  train_df.sort_values(by='igsn', inplace=True )\n",
    "  #convert labels into integers\n",
    "  train_df['iSampleMaterial'] = le.transform(train_df.iSampleMaterial)\n",
    "  \n",
    "# merge the dev dataframes\n",
    "  theframes = [dev_df_min, dev_df_rock, dev_df_sed,dev_df_rocksed,dev_df_soil]\n",
    "  dev_df = pd.concat(theframes)\n",
    "  dev_df.sort_values(by='igsn', inplace=True )\n",
    "  #convert labels into integers\n",
    "  dev_df['iSampleMaterial'] = le.transform(dev_df.iSampleMaterial)\n",
    "\n",
    "# merge the training dataframes\n",
    "  theframes = [test_df_min, test_df_rock, test_df_sed,test_df_rocksed,test_df_soil]\n",
    "  test_df = pd.concat(theframes) \n",
    "  test_df.sort_values(by='igsn', inplace=True )\n",
    "  #convert labels into integers\n",
    "  test_df['iSampleMaterial'] = le.transform(test_df.iSampleMaterial)\n",
    "\n",
    "  train_df.to_csv('output/train_df.csv')\n",
    "  dev_df.to_csv('output/dev_df.csv')\n",
    "  test_df.to_csv('output/test_df.csv')\n",
    "    \n",
    "  return train_df, dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87228d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f3e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required parameters\n",
    "nb_epochs = int(4)  #was 2, then 3, \n",
    "batch_size = int(20) #was 10, then 20, tried 30. now 40 w/5000 samples\n",
    "lr_rate = float(0.007) #was.01\n",
    "\n",
    "# epochs 4, batch 20, lr_rat .007 worked best yet, with 500 samples; lowest loses at 3 epochs\n",
    "# try adding axis = 0 in pandas sampling, I can't tell if its using weights. different results-- sed and rocksed are bad,\n",
    "#  others much better. Run again to see if the same... Get different results. The pandas sample is different, and that \n",
    "# impacts the results. 3 of 5 classes identified prttey well. Try raising sample to 1000.  Got matches on 4 classes, \n",
    "# good only on mineral, rock, and soil.\n",
    "# try sampling w/o weights\n",
    "#  !! worked much better!!\n",
    "\n",
    "# 2023-08-15\n",
    "# try 10 epochs (n-1000, .007, batch 20) to see if get any convergence,no convergence, \n",
    "#        but recall and precision not bad\n",
    "# try 3 epochs, rest same. Seemed to work about as well\n",
    "# try 1 epoch-- seemed to work pretty much the same\n",
    "# try 3 epoch, 40 batch, 5000 samples-- complete fail! \n",
    "# try 3 epoch, 100 batch, 5000 samples\n",
    "# 1 epoch 100 batch 5000, SS's preprocess. Doesn't get any rockSed, otherwise goot\n",
    "# 1 epoch 100 batch, 10000 sample, SS preprocess. didn't get any rockSed or soil...\n",
    "# 4 epoch 100 batch,  10000 sample, SMR preprocess.  TErrible. only got rock\n",
    "# 4 epoch 100 batch,  10000 sample, ss preprocess.  Terrible. only got rock\n",
    "# 3 epoch, 20 batch 10000 sample, ss preprocess rate.01 Bust only got rock\n",
    "# 3 epoch, 20 batch 10000 sample, smr preprocess rate.01 Bust only got rock, but some \n",
    "  # convergences\n",
    "# 4 epoch,batch20,.007,1000 samples, change fractions in training data to favor sed,rocksed. \n",
    "    # good matches except rocksed, but some hits theretoo. Got convergence after the first epoch\n",
    "# try more epochs\n",
    "# 8 epoch,batch20,.007,1000 samples, change fractions in training data to favor sed,rocksed. \n",
    "    # good result rand 42, 23\n",
    "# results vary slightly with different rand\n",
    "# raise n to 2000, rand=73, bad result \n",
    "# try 4 epoch rand= 73\n",
    "\n",
    "\n",
    "\n",
    "material_type = str('')\n",
    "\n",
    "train_mode = str('FALSE')\n",
    "#train_mode = str('custom')\n",
    " #  Whether we account for class imbalance during training by using a custom trainer \n",
    "    # (custom) or not (none)                  \n",
    "output_dir =str('output')\n",
    " #Output directory where the model checkpoint will be saved\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de78509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"iSamplesMaterialTrainingSmall.csv\")\n",
    "# text to read is 'text' column\n",
    "#df = pd.read_csv(\"SESARTrainingiSamKeywords.csv\", usecols=['igsn', 'traintext'],dtype={'igsn':str,'traintext':str})\n",
    "# text to read is 'traintext' column\n",
    "df = pd.read_csv(\"MaterialTypeData2023-08-07.csv\")\n",
    "# text to read is 'text' column\n",
    "\n",
    "df = df.fillna(\"\")\n",
    "    #remove rows that do not have a material type\n",
    "df = df[df[\"text\"]!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ced250",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #load tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', do_lower_case=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e387a",
   "metadata": {},
   "source": [
    "#count tokens-- \n",
    "####################### SLOW-- this scans all records.\n",
    "rowcount = 1\n",
    "ratiosum = 0.0\n",
    "maxratio = 0.0\n",
    "for _, row in df.iterrows():\n",
    "    sentence = row[\"text\"]\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    token_count = len(tokens)\n",
    "    senlen = len(sentence)\n",
    "    ratio = token_count/senlen\n",
    "    if ratio > maxratio:\n",
    "        maxratio = ratio\n",
    "    \n",
    "    #print(\"Original sentence:\", sentence)\n",
    "    #print(\"Sentence len:\", senlen, \"; Number of tokens:\", token_count, \"; ratio:\", ratio)\n",
    "    #print(\"Number of tokens:\", token_count)\n",
    "    \n",
    "    rowcount =rowcount + 1\n",
    "    ratiosum = ratiosum + ratio\n",
    "    #print(\"ratio:\", ratio)\n",
    "    \n",
    "avrage = ratiosum/rowcount\n",
    "print(\"Average ratio:\", avrage, \"; Max ratio:\", maxratio)\n",
    "print(\"row count: \", rowcount)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ab962d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of labels:  5\n"
     ]
    }
   ],
   "source": [
    "#load tokenizer\n",
    "# train(material_type, df, tokenizer, batch_size,lr_rate, nb_epochs, train_mode, output_dir)\n",
    "\n",
    "# insert train function in line here for debugging...\n",
    "#train_df, dev_df, test_df = preprocess_2(df)  #steves update\n",
    "train_df, dev_df, test_df = preprocess(df)  #original function from Sarah Song\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dae570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch tensor dataframe columns: ['igsn' 'isgnprefix' 'text' 'iSampleMaterial' 'weight']\n",
      "torch tensor dataframe columns: ['igsn' 'isgnprefix' 'text' 'iSampleMaterial' 'weight']\n",
      "torch tensor dataframe columns: ['igsn' 'isgnprefix' 'text' 'iSampleMaterial' 'weight']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"train_df columns:\", train_df.columns.values)\n",
    "#print(\"train_df:\", train_df.describe)\n",
    "#train_df['iSampleMaterial'].values\n",
    "\n",
    "train_dataset = create_dataset(train_df, tokenizer)\n",
    "dev_dataset = create_dataset(dev_df,tokenizer)\n",
    "test_dataset = create_dataset(test_df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74223cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_dataset.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ece0d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\", num_labels = len(le.classes_), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63818b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc = model.to(device)\n",
    "training_args = TrainingArguments(\n",
    "          no_cuda = True,\n",
    "          output_dir= output_dir,     # output directory\n",
    "          num_train_epochs=nb_epochs,              # total number of training epochs\n",
    "          per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "          per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "          learning_rate = lr_rate,\n",
    "          warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "          weight_decay=0.01, \n",
    "          load_best_model_at_end=True,            \n",
    "          logging_dir=output_dir,            # directory for storing logs\n",
    "          logging_steps=10,\n",
    "          evaluation_strategy = \"epoch\", #To calculate metrics per epoch\n",
    "          save_strategy = \"epoch\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eff6946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #get class weight\n",
    "class_weights = get_class_weights(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "906eca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomTrainer = create_custom_trainer(class_weights)\n",
    "if train_mode == \"custom\":\n",
    "    trainer = CustomTrainer(model = model, args =training_args, train_dataset=train_dataset, eval_dataset=dev_dataset)\n",
    "else:\n",
    "    trainer = Trainer(model = model, args =training_args, train_dataset=train_dataset, eval_dataset=dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6a236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.labels\n",
    "#train_dataset.encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06516275",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mlclassification\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='635' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 635/1200 1:42:01 < 1:31:04, 0.10 it/s, Epoch 2.11/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.370100</td>\n",
       "      <td>1.526984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.535400</td>\n",
       "      <td>1.779801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in control.should_save. metrics: {'eval_loss': 1.5269842147827148}\n",
      "in control.should_save. metrics: {'eval_loss': 1.7798011302947998}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54410f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #conduct evaluation \n",
    "  keys = []\n",
    "  precision = []\n",
    "  recall = []\n",
    "  f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3178121",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = trainer.predict(test_dataset)[0] #get the logits \n",
    "\n",
    "test_pred = np.argmax(logits,axis=-1)\n",
    "y_test= torch.tensor(test_df['iSampleMaterial'].values.tolist())\n",
    "res = classification_report(y_test,test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd43f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_dataset.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66455d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, score in res.items():\n",
    "  if key.isdigit():\n",
    "    keys.append((le.inverse_transform([int(key)])[0]))\n",
    "    precision.append(round(score['precision'],2))\n",
    "    recall.append(round(score['recall'],2))\n",
    "    f1.append(round(score['f1-score'],2))\n",
    "    print(\"%s \\t\\t\\t %0.2f \\t %0.2f \\t %0.2f\"% (le.inverse_transform([int(key)])[0],score['precision'], score['recall'], score['f1-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cba5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the results to excel and save\n",
    "result_df = pd.DataFrame(data=zip(keys,precision,recall,f1), columns=['label','precision','recall','f1'])\n",
    "result_output_dir =\"output/sesar_result.xlsx\"\n",
    "result_df.to_excel(result_output_dir)\n",
    "print(\"Macro average: \",f1_score(y_test,test_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f998ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
